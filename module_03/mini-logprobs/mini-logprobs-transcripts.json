{
  "notebook": "mini-logprobs.ipynb",
  "module": "Module 2: LLM Core Concepts",
  "total_duration": "~30 min",
  "transcripts": [
    {
      "cell_index": 0,
      "cell_type": "markdown",
      "section": "Introduction",
      "transcript": "Welcome to Token Probabilities! This one is really cool because we get to peek under the hood and see exactly how confident the model is for each token it generates. Log probabilities - or logprobs - let you measure model confidence, detect potential hallucinations, and do clever things like classification without generating text. Let's see how it all works!"
    },
    {
      "cell_index": 1,
      "cell_type": "markdown",
      "section": "1. Setup",
      "transcript": "Quick setup first."
    },
    {
      "cell_index": 2,
      "cell_type": "code",
      "section": "1. Setup",
      "concepts": ["OpenAI client", "numpy", "math module"],
      "transcript": "Standard imports plus numpy and math for the probability conversions. Ready to go!"
    },
    {
      "cell_index": 3,
      "cell_type": "markdown",
      "section": "2. Understanding Log Probabilities",
      "transcript": "First, let's understand what log probabilities actually are. They're just the natural logarithm of the probability."
    },
    {
      "cell_index": 4,
      "cell_type": "code",
      "section": "2. Understanding Log Probabilities",
      "concepts": ["log probability", "probability conversion", "confidence interpretation"],
      "transcript": "This table shows the relationship. 99% probability is logprob of -0.010, very close to zero, meaning highly certain. 50% is -0.693. 10% is -2.303. And 1% is way down at -4.605. The pattern: closer to zero means more confident, more negative means less confident. Why use logs? Numerical stability - very small probabilities can underflow as regular floats, but logs stay manageable. Plus you can add log probs instead of multiplying regular probs for sequences."
    },
    {
      "cell_index": 5,
      "cell_type": "markdown",
      "section": "3. Getting Logprobs from OpenAI API",
      "transcript": "Let's get some actual logprobs from the API."
    },
    {
      "cell_index": 6,
      "cell_type": "code",
      "section": "3. Getting Logprobs from OpenAI API",
      "concepts": ["logprobs parameter", "top_logprobs", "API configuration"],
      "transcript": "Just add logprobs=True and optionally top_logprobs=5 to get the top 5 alternatives for each position. The response is 'The capital of France is Paris.' And logprobs available: True! We've got the data."
    },
    {
      "cell_index": 7,
      "cell_type": "code",
      "section": "3. Getting Logprobs from OpenAI API",
      "concepts": ["token analysis", "confidence visualization", "alternative tokens"],
      "transcript": "Now let's visualize it! Each token with its probability and confidence level. 'The' - 99.98%, marked as certain with the green indicator. 'capital' - 100%! 'of' - 100%. 'France' - 100%. 'is' - 100%. 'Paris' - 100%. Even the period is 100%. This is a factual question with an obvious answer, so the model is extremely confident throughout. And look at the alternatives - for 'Paris', the next options like 'Пари' (Russian) have essentially 0% probability. The model knows exactly what to say here."
    },
    {
      "cell_index": 8,
      "cell_type": "markdown",
      "section": "4. Analyzing Model Confidence",
      "transcript": "Let's compare confidence on different types of prompts."
    },
    {
      "cell_index": 9,
      "cell_type": "code",
      "section": "4. Analyzing Model Confidence",
      "concepts": ["confidence statistics", "factual vs creative prompts", "uncertainty detection"],
      "transcript": "For 'What is 2 + 2?' - average confidence is 99.9%, minimum is 99.1% on 'equals'. All tokens above 50%, no uncertainty at all. Makes sense, this is pure fact. Now the creative prompt - 'Write a creative word that describes happiness' - average drops to 77.2%! And look at the uncertain tokens: 'gl' in 'Joyglow' is only 27.4% confident. The dash, 'radiant', 'state', 'illumin', they're all flagged as uncertain. This is exactly what you'd expect - creative tasks have multiple valid answers, so the model is less sure about its choices."
    },
    {
      "cell_index": 10,
      "cell_type": "markdown",
      "section": "5. Using Logprobs for Classification",
      "transcript": "Here's a powerful technique - using logprobs to get classification confidence."
    },
    {
      "cell_index": 11,
      "cell_type": "code",
      "section": "5. Using Logprobs for Classification",
      "concepts": ["classification confidence", "sentiment analysis", "probability-based classification"],
      "transcript": "We're doing sentiment classification on four texts. 'This product is absolutely amazing!' - Positive with 100% confidence. 'Terrible experience' - Negative, 100% confident. 'Package arrived on time' - hm, Positive at 100%, though you might argue that's Neutral. 'It's okay, nothing special' - Neutral, 100% confident. All high confidence in this case. But the real value is when confidence is lower - that tells you the classification might need human review. You could build a system that auto-classifies when confidence is above 90% and escalates to humans otherwise."
    },
    {
      "cell_index": 12,
      "cell_type": "markdown",
      "section": "6. Perplexity: Measuring Overall Confidence",
      "transcript": "Perplexity gives you a single number for overall sequence confidence."
    },
    {
      "cell_index": 13,
      "cell_type": "code",
      "section": "6. Perplexity: Measuring Overall Confidence",
      "concepts": ["perplexity", "sequence probability", "output comparison"],
      "transcript": "Perplexity is the exponential of negative average log probability. Lower is more confident. 'What is 1 + 1?' - perplexity of 1.00, extremely confident, common output. 'Explain quantum computing briefly' - 1.09, still very confident, this is well-covered territory. 'Write a haiku about a purple elephant' - 1.38, slightly higher but still low. Honestly, models are pretty confident even on creative tasks. Values above 2 would indicate uncertainty, above 5 would be really uncertain. This is useful for comparing outputs or detecting when the model is struggling."
    },
    {
      "cell_index": 14,
      "cell_type": "markdown",
      "section": "7. Practical Application: Hallucination Detection",
      "transcript": "Here's a really practical application - detecting potential hallucinations."
    },
    {
      "cell_index": 15,
      "cell_type": "code",
      "section": "7. Practical Application: Hallucination Detection",
      "concepts": ["hallucination detection", "low confidence tokens", "content verification", "uncertainty flagging"],
      "transcript": "We ask a nonsensical question about 'oceans living on the moon' - the model gives a sensible factual correction that the Moon has no oceans. Now we analyze confidence. With a 30% threshold, we found 1 uncertain claim: the token 'large' at 24.1% confidence in the phrase 'resemble large bodies of water'. It's not really a hallucination here, but the model is less certain about that word choice. In practice, you'd use this to flag claims that need verification. Low confidence doesn't mean wrong, but it's a signal for human review."
    },
    {
      "cell_index": 16,
      "cell_type": "markdown",
      "section": "Summary",
      "transcript": "Let's wrap up! Log probabilities: logprob equals natural log of probability. 0 means certain, more negative means less confident. Convert with prob = e^logprob. Access them with logprobs=True and top_logprobs=N in your API call. Use cases: confidence measurement to know when the model is unsure, classification with probability for each class, hallucination detection by flagging low-confidence claims, and quality filtering to reject uncertain outputs. Perplexity is the aggregate measure - lower is more confident. Next, check out mini-streaming for real-time delivery, mini-model-compare to compare models using logprobs, and Module 8 for using logprobs in evaluation pipelines. Great work everyone!"
    }
  ]
}
