{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§± Lab: Cloud APIs and AI News Briefing Generator\n",
        "\n",
        "**Module 1: Setup & Working Style for LLM Apps** | **Duration: ~1 hour** | **Type: Wall Lab**\n",
        "\n",
        "---\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this lab, you will be able to:\n",
        "\n",
        "1. **Apply** API key management and secrets hygiene practices across multiple LLM providers\n",
        "2. **Build** a reusable web scraper to collect live data from news websites\n",
        "3. **Create** an AI-powered News Briefing Generator using OpenAI and Anthropic\n",
        "4. **Integrate** multiple LLM providers to perform different tasks on the same data\n",
        "\n",
        "## Concepts Covered\n",
        "\n",
        "| Concept | From |\n",
        "|---------|------|\n",
        "| API Keys & Environment Variables | mini-env-setup |\n",
        "| Secrets Hygiene | mini-env-setup |\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- **mini-env-setup**: IDE setup, uv package manager, `.env` configuration with API keys\n",
        "- A payment method for API signups (this lab costs under $0.05 in API calls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Getting Your OpenAI API Key (~5 min)\n",
        "\n",
        "Follow these steps to get your OpenAI API key:\n",
        "\n",
        "### Step 1: Create an Account\n",
        "\n",
        "1. Go to [platform.openai.com](https://platform.openai.com)\n",
        "2. Click **Sign up** (or **Log in** if you already have an account)\n",
        "3. You can sign up with email, Google, Microsoft, or Apple\n",
        "\n",
        "### Step 2: Add a Payment Method\n",
        "\n",
        "1. Once logged in, click the **gear icon** (Settings) in the sidebar\n",
        "2. Navigate to **Billing**\n",
        "3. Click **Add payment method** and enter your card details\n",
        "4. Set a monthly usage limit (recommended: **$5 to $10** for learning)\n",
        "\n",
        "> **Tip:** OpenAI charges per API call based on tokens used. This entire lab costs less than $0.05.\n",
        "\n",
        "### Step 3: Create an API Key\n",
        "\n",
        "1. In the sidebar, click **API Keys**\n",
        "2. Click **Create new secret key**\n",
        "3. Give it a name (e.g., `ai-engineering-course`)\n",
        "4. **Copy the key immediately** â€” you will not be able to see it again!\n",
        "\n",
        "### Step 4: Save to Your .env File\n",
        "\n",
        "```bash\n",
        "# Add this line to your .env file\n",
        "OPENAI_API_KEY=sk-your-key-here\n",
        "```\n",
        "\n",
        "> **Warning:** Never share your API key. Never commit it to git. If you accidentally expose it, rotate it immediately from the dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Getting Your Anthropic (Claude) API Key (~5 min)\n",
        "\n",
        "### Step 1: Create an Account\n",
        "\n",
        "1. Go to [console.anthropic.com](https://console.anthropic.com)\n",
        "2. Click **Sign up**\n",
        "3. Verify your email address\n",
        "\n",
        "### Step 2: Add a Payment Method\n",
        "\n",
        "1. Once logged in, navigate to **Settings** in the sidebar\n",
        "2. Go to **Billing**\n",
        "3. Add a credit or debit card\n",
        "4. Anthropic may offer free credits for new accounts\n",
        "\n",
        "### Step 3: Create an API Key\n",
        "\n",
        "1. In the sidebar, click **API Keys**\n",
        "2. Click **Create Key**\n",
        "3. Give it a name (e.g., `ai-engineering-course`)\n",
        "4. **Copy the key immediately**\n",
        "\n",
        "### Step 4: Save to Your .env File\n",
        "\n",
        "```bash\n",
        "# Add this line to your .env file (below your OpenAI key)\n",
        "ANTHROPIC_API_KEY=sk-ant-your-key-here\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Verify Your .env File\n",
        "\n",
        "Your `.env` file (in your project root) should now have both keys:\n",
        "\n",
        "```bash\n",
        "# .env â€” NEVER commit this to git!\n",
        "OPENAI_API_KEY=sk-your-key-here\n",
        "ANTHROPIC_API_KEY=sk-ant-your-key-here\n",
        "```\n",
        "\n",
        "Make sure `.env` is listed in your `.gitignore` file (covered in **mini-env-setup**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup and Imports (~2 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API Key Status:\n",
            "  OpenAI:    sk-proj-...zKoA\n",
            "  Anthropic: sk-ant-a...RQAA\n",
            "\n",
            "âœ… Setup complete\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Helper function to render LLM output as formatted markdown\n",
        "def md(text):\n",
        "    \"\"\"Display text as rendered markdown.\"\"\"\n",
        "    display(Markdown(text))\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "# Quick check that keys are loaded\n",
        "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
        "\n",
        "def mask_key(key):\n",
        "    \"\"\"Safely mask an API key for display.\"\"\"\n",
        "    if not key:\n",
        "        return \"NOT SET\"\n",
        "    if len(key) < 12:\n",
        "        return \"****\"\n",
        "    return key[:8] + \"...\" + key[-4:]\n",
        "\n",
        "print(\"API Key Status:\")\n",
        "print(f\"  OpenAI:    {mask_key(openai_key)}\")\n",
        "print(f\"  Anthropic: {mask_key(anthropic_key)}\")\n",
        "print(\"\\nâœ… Setup complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialize and Test OpenAI Client\n",
        "\n",
        "The OpenAI Python client automatically reads `OPENAI_API_KEY` from your environment variables â€” no need to pass the key manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… OpenAI client initialized\n",
            "\n",
            "ðŸ§ª Testing OpenAI API Connection\n",
            "==================================================\n",
            "âœ… Connection successful!\n",
            "Response: Hello, AI Engineer!\n",
            "Tokens used: 24\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize client â€” automatically reads OPENAI_API_KEY\n",
        "client = OpenAI()\n",
        "print(\"âœ… OpenAI client initialized\")\n",
        "\n",
        "# Test the connection\n",
        "def test_openai():\n",
        "    \"\"\"Test the OpenAI API connection.\"\"\"\n",
        "    print(\"\\nðŸ§ª Testing OpenAI API Connection\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": \"Say 'Hello, AI Engineer!' in exactly those words.\"}],\n",
        "            max_tokens=20,\n",
        "            temperature=0\n",
        "        )\n",
        "        \n",
        "        print(f\"âœ… Connection successful!\")\n",
        "        print(f\"Response: {response.choices[0].message.content}\")\n",
        "        print(f\"Tokens used: {response.usage.total_tokens}\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Connection failed: {type(e).__name__}\")\n",
        "        print(f\"   Error: {str(e)[:200]}\")\n",
        "        return False\n",
        "\n",
        "test_openai()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Initialize and Test Claude Client\n",
        "\n",
        "The Anthropic Python client works the same way â€” it reads `ANTHROPIC_API_KEY` from your environment automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Anthropic client initialized\n",
            "\n",
            "ðŸ§ª Testing Claude API Connection\n",
            "==================================================\n",
            "âœ… Connection successful! (model: claude-sonnet-4-20250514)\n",
            "Response: Hello, AI Engineer!\n",
            "Tokens used: 28\n"
          ]
        }
      ],
      "source": [
        "import anthropic\n",
        "\n",
        "# Initialize client â€” automatically reads ANTHROPIC_API_KEY\n",
        "anthropic_client = anthropic.Anthropic()\n",
        "print(\"âœ… Anthropic client initialized\")\n",
        "\n",
        "# Test the connection\n",
        "def test_claude():\n",
        "    \"\"\"Test the Anthropic Claude API connection.\"\"\"\n",
        "    print(\"\\nðŸ§ª Testing Claude API Connection\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Try latest model first, then fall back\n",
        "        claude_models = [\"claude-sonnet-4-20250514\", \"claude-3-5-sonnet-latest\"]\n",
        "        \n",
        "        for model_name in claude_models:\n",
        "            try:\n",
        "                response = anthropic_client.messages.create(\n",
        "                    model=model_name,\n",
        "                    max_tokens=30,\n",
        "                    messages=[{\"role\": \"user\", \"content\": \"Say 'Hello, AI Engineer!' in exactly those words.\"}]\n",
        "                )\n",
        "                print(f\"âœ… Connection successful! (model: {model_name})\")\n",
        "                print(f\"Response: {response.content[0].text}\")\n",
        "                print(f\"Tokens used: {response.usage.input_tokens + response.usage.output_tokens}\")\n",
        "                return True, model_name\n",
        "            except Exception:\n",
        "                continue\n",
        "        \n",
        "        print(\"âŒ No compatible Claude model found\")\n",
        "        return False, None\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Connection failed: {type(e).__name__}\")\n",
        "        print(f\"   Error: {str(e)[:200]}\")\n",
        "        return False, None\n",
        "\n",
        "claude_ok, claude_model = test_claude()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. Project: News Briefing Generator\n",
        "\n",
        "Now that both API connections are working, let's build something real!\n",
        "\n",
        "**What we are building:** An AI-powered morning briefing that:\n",
        "\n",
        "1. **Scrapes** today's top headlines from a live news website\n",
        "2. **Summarizes** the key themes using OpenAI (GPT-4o-mini)\n",
        "3. **Categorizes** each story using Claude\n",
        "4. **Displays** a polished morning briefing dashboard\n",
        "\n",
        "This is a real-world pattern you will use throughout your AI engineering career:\n",
        "\n",
        "**Data Collection -> AI Processing -> Useful Output**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Scraping News Headlines\n",
        "\n",
        "We will build a **single, reusable scraping function** that works with any text-heavy news website. The function takes a URL and a CSS selector â€” that is it.\n",
        "\n",
        "**Main example: [NPR Text-Only](https://text.npr.org)** â€” A clean, text-only news page where each story is an `<a>` tag with class `topic-title`. No JavaScript, no clutter.\n",
        "\n",
        "**Other websites you can try** (similar simple HTML structures):\n",
        "\n",
        "| Website | URL | CSS Selector |\n",
        "|---------|-----|--------------|\n",
        "| **NPR** (text-only) | `https://text.npr.org/` | `a.topic-title` |\n",
        "| **CNN Lite** | `https://lite.cnn.com/` | `li > a` |\n",
        "| **Lobsters** (tech news) | `https://lobste.rs/` | `a.u-url` |\n",
        "| **The 68k News** | `https://68k.news/` | `li > a` |\n",
        "\n",
        "> **Tip:** To find the right CSS selector for any site, right-click a headline in your browser, click **Inspect**, and look at the HTML tag and class wrapping each headline link.\n",
        "\n",
        "We only need two libraries:\n",
        "\n",
        "- **requests** â€” fetches the webpage HTML\n",
        "- **BeautifulSoup** â€” parses and extracts data from the HTML\n",
        "\n",
        "The entire scraper is roughly 15 lines of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching https://text.npr.org/...\n",
            "\n",
            "==================================================\n",
            "Scraped 10 stories from https://text.npr.org/\n",
            "   1. What you should know about Bad Bunny's Super Bowl halftime show\n",
            "   2. Hate them or not, Patriots fans want the glory back in Super Bowl LX\n",
            "   3. From Jesus to Jurassic Park: This year's Super Bowl ads are playing it safe\n",
            "   4. He's photographed every Super Bowl. Will this one be his last?\n",
            "   5. U.S. ski star Lindsey Vonn is in 'stable condition' after crash in Olympic downhill\n",
            "   6. Breezy Johnson's downhill gold is America's first medal of 2026 Winter Olympics\n",
            "   7. State Department will delete X posts from before Trump returned to office\n",
            "   8. Immigrant whose skull was broken in 8 places during ICE arrest says beating was unprovoked\n",
            "   9. 'Washington Post' CEO departs after going AWOL during massive job cuts\n",
            "  10. One week since Nancy Guthrie was last seen, here's what we know\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "def scrape_website(url, selector=\"a\", num_stories=10):\n",
        "    \"\"\"\n",
        "    Scrape headlines from any news website.\n",
        "\n",
        "    Args:\n",
        "        url: The webpage URL to scrape\n",
        "        selector: CSS selector to find headline links (default: \"a\")\n",
        "        num_stories: How many stories to return (default: 10)\n",
        "\n",
        "    Returns:\n",
        "        List of dicts with rank, title, link, and source\n",
        "    \"\"\"\n",
        "    print(f\"Fetching {url}...\")\n",
        "    response = requests.get(url, timeout=10)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    stories = []\n",
        "    for idx, item in enumerate(soup.select(selector)[:num_stories], start=1):\n",
        "        title = item.text.strip()\n",
        "        link = item.get(\"href\", \"\")\n",
        "        # Handle relative URLs\n",
        "        if link and not link.startswith(\"http\"):\n",
        "            link = urljoin(url, link)\n",
        "        if title:\n",
        "            stories.append({\n",
        "                \"rank\": str(idx),\n",
        "                \"title\": title,\n",
        "                \"link\": link,\n",
        "                \"source\": url\n",
        "            })\n",
        "\n",
        "    return stories\n",
        "\n",
        "\n",
        "# --- Scrape NPR (main example) ---\n",
        "# To try a different site, swap the url and selector below.\n",
        "# Examples:\n",
        "#   scrape_website(\"https://lite.cnn.com/\", selector=\"li > a\")\n",
        "#   scrape_website(\"https://lobste.rs/\", selector=\"a.u-url\")\n",
        "#   scrape_website(\"https://68k.news/\", selector=\"li > a\")\n",
        "\n",
        "stories = scrape_website(\n",
        "    url=\"https://text.npr.org/\",\n",
        "    selector=\"a.topic-title\",\n",
        "    num_stories=10\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Scraped {len(stories)} stories from {stories[0]['source'] if stories else 'N/A'}\")\n",
        "for s in stories:\n",
        "    print(f\"  {s['rank']:>2}. {s['title']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Generate a Morning Briefing with OpenAI\n",
        "\n",
        "Now let's send these headlines to GPT-4o-mini and ask it to write a concise morning briefing â€” like a tech newsletter editor would."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending headlines to OpenAI...\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## OpenAI's Morning Briefing\n",
              "\n",
              "### Morning Briefing: Key Headlines for Today\n",
              "\n",
              "As the excitement builds for Super Bowl LX, Bad Bunny's highly anticipated halftime show is a focal point, promising a unique blend of entertainment that fans won't want to miss. Meanwhile, the New England Patriots, despite recent struggles, are rallying their fanbase with hopes of reclaiming their former glory on the big stage. This year's Super Bowl advertisements appear to tread cautiously, featuring familiar themes ranging from spiritual to nostalgic, as brands aim to resonate with a broad audience.\n",
              "\n",
              "In sports news, former Olympic skier Lindsey Vonn is reported to be in stable condition following a crash during the Olympic downhill event, while Breezy Johnson clinched America's first gold medal at the 2026 Winter Olympics. On the political front, the State Department is set to delete Twitter posts from before Trump's return to office, stirring discussions about transparency. Additionally, the departure of the Washington Post CEO amidst significant layoffs raises questions about the future of media leadership. Lastly, the mysterious disappearance of Nancy Guthrie continues to develop, with authorities providing updates on the ongoing investigation."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Prepare headlines as plain text for the LLM\n",
        "headlines_text = \"\\n\".join([f\"{s['rank']}. {s['title']}\" for s in stories])\n",
        "\n",
        "print(\"Sending headlines to OpenAI...\\n\")\n",
        "\n",
        "# Generate briefing with OpenAI\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are a news editor writing a concise morning briefing. \"\n",
        "                \"Be informative and highlight what matters most.\"\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                f\"Here are today's top stories:\\n\\n\"\n",
        "                f\"{headlines_text}\\n\\n\"\n",
        "                f\"Write a 2-3 paragraph morning briefing summarizing the key themes \"\n",
        "                f\"and most important stories. Use markdown formatting.\"\n",
        "            )\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=500,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "openai_briefing = response.choices[0].message.content\n",
        "\n",
        "md(f\"## OpenAI's Morning Briefing\\n\\n{openai_briefing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3 Categorize Headlines with Claude\n",
        "\n",
        "Now let's send the same headlines to Claude and ask it to categorize each story and pick the must-read for an AI engineer.\n",
        "\n",
        "Notice how we use the same data but ask each model to do a **different task** â€” this is a common multi-model pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending headlines to Claude...\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Claude's Analysis\n",
              "\n",
              "| Title | Category | Relevance |\n",
              "|-------|----------|-----------|\n",
              "| What you should know about Bad Bunny's Super Bowl halftime show | Culture | Low |\n",
              "| Hate them or not, Patriots fans want the glory back in Super Bowl LX | Culture | Low |\n",
              "| From Jesus to Jurassic Park: This year's Super Bowl ads are playing it safe | Culture | Low |\n",
              "| He's photographed every Super Bowl. Will this one be his last? | Culture | Low |\n",
              "| U.S. ski star Lindsey Vonn is in 'stable condition' after crash in Olympic downhill | Other | Low |\n",
              "| Breezy Johnson's downhill gold is America's first medal of 2026 Winter Olympics | Other | Low |\n",
              "| State Department will delete X posts from before Trump returned to office | Politics | Low |\n",
              "| Immigrant whose skull was broken in 8 places during ICE arrest says beating was unprovoked | Politics | Low |\n",
              "| 'Washington Post' CEO departs after going AWOL during massive job cuts | Business | Medium |\n",
              "| One week since Nancy Guthrie was last seen, here's what we know | Other | Low |\n",
              "\n",
              "**Must-read story for an AI engineer:** 'Washington Post' CEO departs after going AWOL during massive job cuts\n",
              "\n",
              "This story provides insight into major organizational changes at a leading media company that likely employs AI engineers and uses AI technology extensively in content creation and distribution. Understanding leadership instability and restructuring at tech-forward media organizations can offer valuable perspective on industry trends and potential career implications for AI professionals working in or considering the media sector."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Sending headlines to Claude...\\n\")\n",
        "\n",
        "# Use the model that worked during our test, or fall back to a default\n",
        "model_to_use = claude_model if claude_model else \"claude-sonnet-4-20250514\"\n",
        "\n",
        "response = anthropic_client.messages.create(\n",
        "    model=model_to_use,\n",
        "    max_tokens=800,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                f\"Here are today's top stories:\\n\\n\"\n",
        "                f\"{headlines_text}\\n\\n\"\n",
        "                f\"For each story:\\n\"\n",
        "                f\"1. Assign a category: AI, Web Dev, Security, Business, Science, Politics, Culture, or Other\\n\"\n",
        "                f\"2. Rate its relevance for an AI engineer: High, Medium, or Low\\n\\n\"\n",
        "                f\"Present this as a markdown table with columns: Title, Category, Relevance.\\n\\n\"\n",
        "                f\"Then pick the number 1 must-read story for an AI engineer and explain why in 2 sentences.\"\n",
        "            )\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "claude_analysis = response.content[0].text\n",
        "\n",
        "md(f\"## Claude's Analysis\\n\\n{claude_analysis}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.4 Your AI Morning Briefing Dashboard\n",
        "\n",
        "Let's combine everything into a polished, single-view dashboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Your Morning Briefing\n",
              "Powered by Live News + OpenAI + Claude\n",
              "\n",
              "---\n",
              "\n",
              "## Top Stories from https://text.npr.org/\n",
              "\n",
              "**1.** [What you should know about Bad Bunny's Super Bowl halftime show](https://text.npr.org/nx-s1-5698518)\n",
              "\n",
              "**2.** [Hate them or not, Patriots fans want the glory back in Super Bowl LX](https://text.npr.org/nx-s1-5692947)\n",
              "\n",
              "**3.** [From Jesus to Jurassic Park: This year's Super Bowl ads are playing it safe](https://text.npr.org/nx-s1-5697056)\n",
              "\n",
              "**4.** [He's photographed every Super Bowl. Will this one be his last?](https://text.npr.org/nx-s1-5690373)\n",
              "\n",
              "**5.** [U.S. ski star Lindsey Vonn is in 'stable condition' after crash in Olympic downhill](https://text.npr.org/nx-s1-5705859)\n",
              "\n",
              "**6.** [Breezy Johnson's downhill gold is America's first medal of 2026 Winter Olympics](https://text.npr.org/nx-s1-5705898)\n",
              "\n",
              "**7.** [State Department will delete X posts from before Trump returned to office](https://text.npr.org/nx-s1-5704785)\n",
              "\n",
              "**8.** [Immigrant whose skull was broken in 8 places during ICE arrest says beating was unprovoked](https://text.npr.org/g-s1-109219)\n",
              "\n",
              "**9.** ['Washington Post' CEO departs after going AWOL during massive job cuts](https://text.npr.org/nx-s1-5705413)\n",
              "\n",
              "**10.** [One week since Nancy Guthrie was last seen, here's what we know](https://text.npr.org/nx-s1-5705280)\n",
              "\n",
              "---\n",
              "\n",
              "## Summary (GPT-4o-mini)\n",
              "\n",
              "### Morning Briefing: Key Headlines for Today\n",
              "\n",
              "As the excitement builds for Super Bowl LX, Bad Bunny's highly anticipated halftime show is a focal point, promising a unique blend of entertainment that fans won't want to miss. Meanwhile, the New England Patriots, despite recent struggles, are rallying their fanbase with hopes of reclaiming their former glory on the big stage. This year's Super Bowl advertisements appear to tread cautiously, featuring familiar themes ranging from spiritual to nostalgic, as brands aim to resonate with a broad audience.\n",
              "\n",
              "In sports news, former Olympic skier Lindsey Vonn is reported to be in stable condition following a crash during the Olympic downhill event, while Breezy Johnson clinched America's first gold medal at the 2026 Winter Olympics. On the political front, the State Department is set to delete Twitter posts from before Trump's return to office, stirring discussions about transparency. Additionally, the departure of the Washington Post CEO amidst significant layoffs raises questions about the future of media leadership. Lastly, the mysterious disappearance of Nancy Guthrie continues to develop, with authorities providing updates on the ongoing investigation.\n",
              "\n",
              "---\n",
              "\n",
              "## Story Analysis (Claude Sonnet)\n",
              "\n",
              "| Title | Category | Relevance |\n",
              "|-------|----------|-----------|\n",
              "| What you should know about Bad Bunny's Super Bowl halftime show | Culture | Low |\n",
              "| Hate them or not, Patriots fans want the glory back in Super Bowl LX | Culture | Low |\n",
              "| From Jesus to Jurassic Park: This year's Super Bowl ads are playing it safe | Culture | Low |\n",
              "| He's photographed every Super Bowl. Will this one be his last? | Culture | Low |\n",
              "| U.S. ski star Lindsey Vonn is in 'stable condition' after crash in Olympic downhill | Other | Low |\n",
              "| Breezy Johnson's downhill gold is America's first medal of 2026 Winter Olympics | Other | Low |\n",
              "| State Department will delete X posts from before Trump returned to office | Politics | Low |\n",
              "| Immigrant whose skull was broken in 8 places during ICE arrest says beating was unprovoked | Politics | Low |\n",
              "| 'Washington Post' CEO departs after going AWOL during massive job cuts | Business | Medium |\n",
              "| One week since Nancy Guthrie was last seen, here's what we know | Other | Low |\n",
              "\n",
              "**Must-read story for an AI engineer:** 'Washington Post' CEO departs after going AWOL during massive job cuts\n",
              "\n",
              "This story provides insight into major organizational changes at a leading media company that likely employs AI engineers and uses AI technology extensively in content creation and distribution. Understanding leadership instability and restructuring at tech-forward media organizations can offer valuable perspective on industry trends and potential career implications for AI professionals working in or considering the media sector.\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "today = datetime.now().strftime(\"%A, %B %d, %Y\")\n",
        "source_name = stories[0][\"source\"] if stories else \"News\"\n",
        "\n",
        "# Build headline links\n",
        "headline_links = \"\\n\\n\".join([\n",
        "    f\"**{s['rank']}.** [{s['title']}]({s['link']})\"\n",
        "    for s in stories\n",
        "])\n",
        "\n",
        "# Display the complete briefing\n",
        "md(f\"\"\"# Your Morning Briefing\n",
        "Powered by Live News + OpenAI + Claude\n",
        "\n",
        "---\n",
        "\n",
        "## Top Stories from {source_name}\n",
        "\n",
        "{headline_links}\n",
        "\n",
        "---\n",
        "\n",
        "## Summary (GPT-4o-mini)\n",
        "\n",
        "{openai_briefing}\n",
        "\n",
        "---\n",
        "\n",
        "## Story Analysis (Claude Sonnet)\n",
        "\n",
        "{claude_analysis}\n",
        "\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Challenge: Extend Your Briefing\n",
        "\n",
        "Try these extensions on your own:\n",
        "\n",
        "1. **Try a different source** â€” Swap the URL and selector to scrape CNN Lite (`https://lite.cnn.com/`, selector `li > a`) or Lobsters (`https://lobste.rs/`, selector `a.u-url`)\n",
        "2. **Scrape multiple sites** â€” Call `scrape_website()` with different URLs and combine the results into one list\n",
        "3. **Filter by topic** â€” Add a parameter to only show AI-related stories\n",
        "4. **Sentiment analysis** â€” Ask the LLM to rate each headline's sentiment (positive, negative, neutral)\n",
        "5. **Compare models** â€” Try `gpt-4o` instead of `gpt-4o-mini`. Is the briefing better? Worth the extra cost?\n",
        "6. **Personalize it** â€” Add a system prompt that tailors the briefing to your specific interests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Summary\n",
        "\n",
        "### What You Built\n",
        "\n",
        "You built a real AI-powered application that:\n",
        "\n",
        "- **Collects** live data from a news website using a single reusable scraper function\n",
        "- **Processes** it with two different LLMs (OpenAI and Claude)\n",
        "- **Produces** a useful, formatted output (Morning Briefing Dashboard)\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **API Key Setup** â€” Both OpenAI and Anthropic follow the same pattern: sign up, add payment, create key, save to `.env`\n",
        "2. **Client Initialization** â€” Both clients auto-read API keys from environment variables\n",
        "3. **Web Scraping** â€” `requests` + `BeautifulSoup` is all you need for simple HTML sites. One function with a URL and CSS selector can scrape many different websites.\n",
        "4. **Multi-Model Usage** â€” Different models can serve different roles (summarization vs. classification)\n",
        "5. **Real-World Pattern** â€” Data Collection, then AI Processing, then Useful Output is a core AI engineering workflow\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **mini-ollama-setup**: Set up local LLMs with Ollama (free, private, no API key needed)\n",
        "- **lab-hello-llm**: Build your first LLM-powered app with model switching"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "text_llm_agent",
      "language": "python",
      "name": "text_llm_agent"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
